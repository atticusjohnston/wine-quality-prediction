{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T23:41:03.929172Z",
     "start_time": "2024-04-22T23:41:03.926961Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 392
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:41:04.069197Z",
     "start_time": "2024-04-22T23:41:04.067378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def notify(title, text, model):\n",
    "    os.system(\"\"\"\n",
    "              osascript -e 'display notification \"{}\" with title \"{}\"'\n",
    "              \"\"\".format(text, title))\n",
    "    # os.system(f'say \"{model.__class__.__name__} training complete!\"')"
   ],
   "id": "99ba406598c75c72",
   "outputs": [],
   "execution_count": 393
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:41:04.077309Z",
     "start_time": "2024-04-22T23:41:04.071702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rawWhitesDF = pd.read_csv(\"raw-wine-data/winequality-white.csv\", delimiter=\";\")\n",
    "rawRedsDF = pd.read_csv(\"raw-wine-data/winequality-red.csv\", delimiter=\";\")"
   ],
   "id": "d7bdcadd3cb71efb",
   "outputs": [],
   "execution_count": 394
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:41:04.083156Z",
     "start_time": "2024-04-22T23:41:04.077993Z"
    }
   },
   "cell_type": "code",
   "source": "rawWhitesDF.head()",
   "id": "de6c52d8b07f2a33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 395
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:41:04.093938Z",
     "start_time": "2024-04-22T23:41:04.088634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "featureLabels = list(rawWhitesDF.columns.values)\n",
    "classes = [c for c in range(1, 11)]\n",
    "\n",
    "# Normalising the continuous data with MinMax scaling\n",
    "scaledWhitesDF = rawWhitesDF.copy()\n",
    "scaledRedsDF = rawRedsDF.copy()\n",
    "\n",
    "for column in featureLabels[:-1]:\n",
    "    scaledWhitesDF[column] = (scaledWhitesDF[column] - scaledWhitesDF[column].min()) / (scaledWhitesDF[column].max() - scaledWhitesDF[column].min())\n",
    "    scaledRedsDF[column] = (scaledRedsDF[column] - scaledRedsDF[column].min()) / (scaledRedsDF[column].max() - scaledRedsDF[column].min())"
   ],
   "id": "e8d4dfecea288533",
   "outputs": [],
   "execution_count": 396
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:41:04.104154Z",
     "start_time": "2024-04-22T23:41:04.101144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "whiteTargetsInt = torch.tensor(scaledWhitesDF['quality'].to_numpy())\n",
    "whiteFeatures = torch.tensor(scaledWhitesDF[featureLabels[0:-1]].to_numpy(), requires_grad=True, dtype=torch.float32)\n",
    "\n",
    "redTargetsInt = torch.tensor(scaledRedsDF['quality'].to_numpy())\n",
    "redFeatures = torch.tensor(scaledRedsDF[featureLabels[0:-1]].to_numpy(), requires_grad=True, dtype=torch.float32)"
   ],
   "id": "6653419db253c007",
   "outputs": [],
   "execution_count": 397
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:41:04.146715Z",
     "start_time": "2024-04-22T23:41:04.120944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "whiteTargets =  []\n",
    "\n",
    "for i, target in enumerate(whiteTargetsInt):\n",
    "    embed = torch.zeros(len(classes), dtype=torch.float32)\n",
    "    embed[target.item()-1] = 1\n",
    "    whiteTargets.append(embed)\n",
    "whiteTargets = torch.stack(whiteTargets).to(torch.float32)\n",
    "\n",
    "redTargets = []\n",
    "\n",
    "for i, target in enumerate(redTargetsInt):\n",
    "    embed = torch.zeros(len(classes), dtype=torch.float32)\n",
    "    embed[target.item()-1] = 1\n",
    "    redTargets.append(embed)\n",
    "redTargets = torch.stack(redTargets).to(torch.float32)"
   ],
   "id": "40f6e671c072ec42",
   "outputs": [],
   "execution_count": 398
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:41:04.169821Z",
     "start_time": "2024-04-22T23:41:04.167027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            'features': self.features[idx],\n",
    "            'target': self.targets[idx]\n",
    "        }\n",
    "        return sample"
   ],
   "id": "932790ca7a7c8456",
   "outputs": [],
   "execution_count": 399
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:41:04.212770Z",
     "start_time": "2024-04-22T23:41:04.209255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_indices, test_indices = train_test_split(range(len(whiteFeatures)), test_size=0.2, random_state=57)\n",
    "train_indices, val_indices = train_test_split(train_indices, test_size=0.1, random_state=57)"
   ],
   "id": "15c63b5b1388833c",
   "outputs": [],
   "execution_count": 400
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:41:04.242701Z",
     "start_time": "2024-04-22T23:41:04.238778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = WineDataset(whiteFeatures[train_indices], whiteTargets[train_indices])\n",
    "val_dataset = WineDataset(whiteFeatures[val_indices], whiteTargets[val_indices])\n",
    "test_dataset = WineDataset(whiteFeatures[test_indices], whiteTargets[test_indices])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "red_test_dataset = WineDataset(redFeatures, redTargets)\n",
    "red_test_loader = DataLoader(dataset=red_test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "474b067400571750",
   "outputs": [],
   "execution_count": 401
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:41:04.275104Z",
     "start_time": "2024-04-22T23:41:04.270540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class FeedForwardModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FeedForwardModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, input_channels, output_size, hidden_size):\n",
    "        super(ConvModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64, hidden_size)  \n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        # Convolutional layers\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        # Flatten\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        # Fully connected layers\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers, num_heads, hidden_size, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        # Transformer encoder layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(hidden_size, num_heads, hidden_size, dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply embedding\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = x.unsqueeze(1) # (batch_size, seq_len, hidden_size)\n",
    "        \n",
    "        # Apply transformer encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        x = x.squeeze(1) # (batch_size, hidden_size)\n",
    "        \n",
    "        # Apply output layer\n",
    "        x = self.relu(self.output_layer(x))\n",
    "\n",
    "        return x"
   ],
   "id": "9bef2aef72b9e27",
   "outputs": [],
   "execution_count": 402
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:41:04.291093Z",
     "start_time": "2024-04-22T23:41:04.286812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, device, train_loader, optimiser, nepoch, scheduler_step_size, scheduler_gamma):\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimiser, step_size=scheduler_step_size, gamma=scheduler_gamma)\n",
    "    model.to(device)\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    # for epoch in range(nepoch):\n",
    "    for epoch in tqdm(range(nepoch), leave=False, unit='epoch', desc= \"Epochs\"):\n",
    "        \n",
    "        total_train_loss = 0\n",
    "        train_count = 0\n",
    "        total_val_loss = 0\n",
    "        val_count = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            inputs, targets = batch['features'], batch['target']\n",
    "            inputs, targets = inputs.to(device).detach(), targets.to(device).detach()\n",
    "            \n",
    "            optimiser.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            train_loss = criterion(outputs, targets)\n",
    "            train_loss.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            total_train_loss += train_loss.item()\n",
    "            train_count += 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs, targets = batch['features'], batch['target']\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                val_loss = criterion(outputs, targets)\n",
    "                \n",
    "                total_val_loss += val_loss.item()\n",
    "                val_count += 1\n",
    "        \n",
    "        train_losses.append(total_train_loss/train_count)\n",
    "        val_losses.append(total_val_loss/val_count)\n",
    "        scheduler.step()\n",
    "    \n",
    "    plt.semilogy(train_losses)\n",
    "    plt.semilogy(val_losses)\n",
    "    plt.legend([\"Train loss\", \"Val. loss\"])\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "    notify(\"Training Finished\", \"\", model)\n",
    "    # print(\"Final training loss:  \", round(train_losses[-1], 4))\n",
    "    # print(\"Final validation loss:\", round(val_losses[-1], 4))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.to(device)\n",
    "    \n",
    "    correct, total = 0, 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            inputs, targets = batch['features'], batch['target']\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # predicted = torch.argmax(outputs, dim=1)\n",
    "            predicted = torch.topk(outputs, 2, dim=1).indices\n",
    "            actual = torch.argmax(targets, dim=1)\n",
    "            \n",
    "            total += targets.size(0)\n",
    "            correct += torch.sum(torch.any(predicted.eq(actual.unsqueeze(1)), dim=1)).item() # ChatGPT output. Include in write-up.\n",
    "            \n",
    "    acc = round(100 * correct / total, 4)\n",
    "    return acc"
   ],
   "id": "2d1b677378fc6712",
   "outputs": [],
   "execution_count": 403
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-04-22T23:41:04.301278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseModel = TransformerModel(input_size=whiteFeatures.shape[1], output_size=len(classes), num_layers=10, num_heads=16, hidden_size=128, dropout=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "baseOptimiser = torch.optim.Adam(baseModel.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_built() else \"cpu\")\n",
    "\n",
    "scheduler_step_size = 100\n",
    "scheduler_gamma = 0.1\n",
    "nepoch = 300\n",
    "\n",
    "train(baseModel, device, train_loader, baseOptimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "9ffa7a01f42acd3a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Epochs:   0%|          | 0/300 [00:00<?, ?epoch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe5dc7608ac44246ab88aed2e521b623"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the base model on withheld white wine data.\n",
    "white_base_acc = test(baseModel, device, test_loader)\n",
    "print(\"Base model top-2 accuracy on white wine dataset:\", white_base_acc)"
   ],
   "id": "7fa2d2ed08a9d9de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Printing model summary\n",
    "import torchinfo\n",
    "print(torchinfo.summary(baseModel, (64, 11), col_names = (\"input_size\", \"output_size\", \"num_params\")))"
   ],
   "id": "b492c071ad6a412f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Computational Experiment 1: Testing base model generalisability on red wine dataset.",
   "id": "69e193f2e30013c5"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the model on red wine data.\n",
    "red_base_acc = test(baseModel, device, red_test_loader)\n",
    "print(\"Base model top-2 accuracy on red wine dataset:\", red_base_acc)"
   ],
   "id": "d491cfe08e04fd13",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Computational Experiment 2: Comparing performance of transformer, feed-forward and CNN.",
   "id": "ce3178a3b98e689c"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "FFModel = FeedForwardModel(input_size=whiteFeatures.shape[1], output_size=len(classes),hidden_size=128)\n",
    "FFOptimiser = torch.optim.Adam(FFModel.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "train(FFModel, device, train_loader, FFOptimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "a1ebc58fe6bc58a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the feed-forward model on withheld white wine data.\n",
    "white_FF_acc = test(FFModel, device, test_loader)\n",
    "print(\"Feed-forward model top-2 accuracy on white wine dataset:\", white_FF_acc) # "
   ],
   "id": "6fb6a62f9c42d3b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Pretty similar. Makes sense since Transformers are best at sequential because of the multi-head attention. Might not even be worth using transformers because of the much longer training time.  \\\n",
    "    - ~6 mins to train transformer \\\n",
    "    - "
   ],
   "id": "e7c5f51cfec8fc2c"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "CNNModel = ConvModel(input_channels=1, output_size=len(classes), hidden_size=128)\n",
    "CNNOptimiser = torch.optim.Adam(CNNModel.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "train(CNNModel, device, train_loader, CNNOptimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "5e5cbd6b70f24a7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the CNN model on withheld white wine data.\n",
    "white_CNN_acc = test(CNNModel, device, test_loader)\n",
    "print(\"CNN model top-2 accuracy on white wine dataset:\", white_CNN_acc) # "
   ],
   "id": "25acda5ed03c3420",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You could call the three all even since I spent the most time toying with the transformer model hyperparameters trying to get it optimal. Not how well each of them works, its how well they work in unison.",
   "id": "3ab0e9f5d4229015"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Computational Experiment 3: ",
   "id": "738199fae4ee79df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Testing dropout at 20%.",
   "id": "1c9d04c3e2979d92"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "drop20Model = TransformerModel(input_size=whiteFeatures.shape[1], output_size=len(classes), num_layers=10, num_heads=16, hidden_size=128, dropout=0.2)\n",
    "drop20Optimiser = torch.optim.Adam(drop20Model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "train(drop20Model, device, train_loader, drop20Optimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "1ebb754b8637369d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the dropout-20% model on withheld white wine data.\n",
    "white_drop20_acc = test(drop20Model, device, test_loader)\n",
    "print(\"Dropout-20% model top-2 accuracy on white wine dataset:\", white_drop20_acc)"
   ],
   "id": "4499e75fcf147c58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Variations in number of layers",
   "id": "f14975c08b1576b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4 hidden layers",
   "id": "b68b31fdf57aecdb"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "hidden4Model = TransformerModel(input_size=whiteFeatures.shape[1], output_size=len(classes), num_layers=4, num_heads=16, hidden_size=128, dropout=0.5)\n",
    "hidden4Optimiser = torch.optim.Adam(hidden4Model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "train(hidden4Model, device, train_loader, hidden4Optimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "48225677a712f619",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the hidden-4 model on withheld white wine data.\n",
    "white_hidden4_acc = test(hidden4Model, device, test_loader)\n",
    "print(\"Hidden-4 model top-2 accuracy on white wine dataset:\", white_hidden4_acc)"
   ],
   "id": "fb9bc161ecfdb20a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5 hidden layers",
   "id": "7117c58430927fa6"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "hidden5Model = TransformerModel(input_size=whiteFeatures.shape[1], output_size=len(classes), num_layers=5, num_heads=16, hidden_size=128, dropout=0.5)\n",
    "hidden5Optimiser = torch.optim.Adam(hidden5Model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "train(hidden5Model, device, train_loader, hidden5Optimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "50923576ef9f5cdd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the hidden-5 model on withheld white wine data.\n",
    "white_hidden5_acc = test(hidden5Model, device, test_loader)\n",
    "print(\"Hidden-5 model top-2 accuracy on white wine dataset:\", white_hidden5_acc)"
   ],
   "id": "1606cd4b36ad7283",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "6 hidden layers",
   "id": "1123b32c64c30b80"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "hidden6Model = TransformerModel(input_size=whiteFeatures.shape[1], output_size=len(classes), num_layers=6, num_heads=16, hidden_size=128, dropout=0.5)\n",
    "hidden6Optimiser = torch.optim.Adam(hidden6Model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "train(hidden6Model, device, train_loader, hidden6Optimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "7903666429933ac8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the hidden-5 model on withheld white wine data.\n",
    "white_hidden6_acc = test(hidden6Model, device, test_loader)\n",
    "print(\"Hidden-6 model top-2 accuracy on white wine dataset:\", white_hidden6_acc)"
   ],
   "id": "606dbe1fb33e6eef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "7 hidden layers",
   "id": "66934466a7e36e1e"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "hidden7Model = TransformerModel(input_size=whiteFeatures.shape[1], output_size=len(classes), num_layers=7, num_heads=16, hidden_size=128, dropout=0.5)\n",
    "hidden7Optimiser = torch.optim.Adam(hidden7Model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "train(hidden7Model, device, train_loader, hidden7Optimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "7fbd9d54fc1109f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the hidden-5 model on withheld white wine data.\n",
    "white_hidden7_acc = test(hidden7Model, device, test_loader)\n",
    "print(\"Hidden-7 model top-2 accuracy on white wine dataset:\", white_hidden7_acc)"
   ],
   "id": "e193b6d7cdee3e8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "8 hidden layers",
   "id": "bca95a931117210a"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "hidden8Model = TransformerModel(input_size=whiteFeatures.shape[1], output_size=len(classes), num_layers=8, num_heads=16, hidden_size=128, dropout=0.5)\n",
    "hidden8Optimiser = torch.optim.Adam(hidden8Model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "train(hidden8Model, device, train_loader, hidden8Optimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "c6dd22576e61a784",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the hidden-5 model on withheld white wine data.\n",
    "white_hidden8_acc = test(hidden8Model, device, test_loader)\n",
    "print(\"Hidden-8 model top-2 accuracy on white wine dataset:\", white_hidden8_acc)"
   ],
   "id": "e72afc92c5f315d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "9 hidden layers",
   "id": "edb70d5ffa753cd7"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "hidden9Model = TransformerModel(input_size=whiteFeatures.shape[1], output_size=len(classes), num_layers=9, num_heads=16, hidden_size=128, dropout=0.5)\n",
    "hidden9Optimiser = torch.optim.Adam(hidden9Model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "train(hidden9Model, device, train_loader, hidden9Optimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "eb6bdae8c028579c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the hidden-5 model on withheld white wine data.\n",
    "white_hidden9_acc = test(hidden9Model, device, test_loader)\n",
    "print(\"Hidden-9 model top-2 accuracy on white wine dataset:\", white_hidden9_acc)"
   ],
   "id": "54a2ea666c3e16c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "10 hidden layers",
   "id": "17ba27a87b470526"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "hidden10Model = TransformerModel(input_size=whiteFeatures.shape[1], output_size=len(classes), num_layers=10, num_heads=16, hidden_size=128, dropout=0.5)\n",
    "hidden10Optimiser = torch.optim.Adam(hidden10Model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "train(hidden10Model, device, train_loader, hidden10Optimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "b68e02925bfe41f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the hidden-5 model on withheld white wine data.\n",
    "white_hidden10_acc = test(hidden10Model, device, test_loader)\n",
    "print(\"Hidden-10 model top-2 accuracy on white wine dataset:\", white_hidden10_acc)"
   ],
   "id": "69d0244c9fd8f231",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "11 hidden layers",
   "id": "4013016ff0dbc58f"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "hidden11Model = TransformerModel(input_size=whiteFeatures.shape[1], output_size=len(classes), num_layers=11, num_heads=16, hidden_size=128, dropout=0.5)\n",
    "hidden11Optimiser = torch.optim.Adam(hidden11Model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "train(hidden11Model, device, train_loader, hidden11Optimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "5477b9a3ae6fe9df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the hidden-5 model on withheld white wine data.\n",
    "white_hidden11_acc = test(hidden11Model, device, test_loader)\n",
    "print(\"Hidden-11 model top-2 accuracy on white wine dataset:\", white_hidden11_acc)"
   ],
   "id": "fcfb3e636a53d079",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "12 hidden layers",
   "id": "4357adefa40ba34"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "hidden12Model = TransformerModel(input_size=whiteFeatures.shape[1], output_size=len(classes), num_layers=12, num_heads=16, hidden_size=128, dropout=0.5)\n",
    "hidden12Optimiser = torch.optim.Adam(hidden12Model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "train(hidden12Model, device, train_loader, hidden12Optimiser, nepoch, scheduler_step_size, scheduler_gamma)"
   ],
   "id": "80183767453657e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Testing the hidden-5 model on withheld white wine data.\n",
    "white_hidden12_acc = test(hidden12Model, device, test_loader)\n",
    "print(\"Hidden-12 model top-2 accuracy on white wine dataset:\", white_hidden12_acc)"
   ],
   "id": "3038154cb9e496b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Varying ",
   "id": "24ea59a481f1bcc3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
